<html>
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="utf-8">
</head>
<body>

<h1>About this document</h1>
<p>
    This document is intended to serve as a resource for other developers to get a familiarity for how the different parts of the Affordable Medical Ultrasound Training Simulator function together. It is <em>not</em> a look at every nook-and-cranny in the entire codebase, but an informal top-down walkthrough to guide you through the data flow and structure of the project. It should be accompanied by class documentation at <a href="./Docs/html/index.html" target="_blank">./Docs/html/index.html</a> - there are links to docs pages that may be broken if the class documentation isn't located there.
</p>
<p>
    I am assuming that you already have some experience with Unity3D - at least enough to understand terms like "Inspector", "MonoBehaviour", "Component", and "Raycast". I am also assuming that you have a bit of background knowledge about medical ultrasound procedures and physics - at least enough to understand terms like "B-mode" and "acoustic impedance".
</p>
<p>
    <em>Logan M Hood</em><br/>
    2014-05-01
</p>

<h1>Overview</h1>
<p>
    The "Affordable Medical Ultrasound Training Simulator" project (henceforth referred to as just "the simulator") is in fact two separate modules:
    <ol>
        <li>HORAY: <u>HO</u>mogeneous Tissue Model <u>RAY</u>casting. This is an ultrasound image simulation package. It uses Unity3D's raycasting and collisions library in conjunction with 3D mesh models to simulate a 2D B-Mode ultrasound imaging system. It operates under the assumption that tissues can be represented as homogeneous mesh models.</li>
        <li>A host Unity3D project for interacting with medical image simulations, displaying the images generated by the simulation and allowing the user to interact with a probe or other parameters of the simulation.</li>
    </ol>
    Currently, HORAY is the only simulation compatible with this host program, but for purposes of abstraction, it is useful to think of the "host" user interaction layer as a completely independent module from the underlying simulation.
</p>

<h1>The Basic Geometry Scene</h1>
<p>
    A good entry point to understanding the Simulator is the "Basic Geometry" scene. This is its path in the project folder:<br/>
    <strong>Assets/Scenes/TestScenes/horayValidationTests/basicGeometry.unity</strong><br/>
    Open this scene in the Unity editor.
</p>
<p>
    There are five objects in the scene:
    <ul>
        <li>The probe (a blue cube)</li>
        <li>The display (a large, flat, rectangular object)</li>
        <li>Three white "organs" - a sphere, a capsule, and a cube.</li>
    </ul>
</p>
<p>
    When you run the scene, you'll see a black and white image rendered to the display. This image is actually a simulated ultrasound image - it's just a cross-section of the organs in the scene, from the perspective of the blue cube. Initially, you're seeing a slice going through the "ground" plane (y = 0). Try moving the cube around in the Scene view while the scene is running, and you'll see the image change accordingly.
</p>

<h1>The Display GameObject</h1>
<p>
    The first object we'll look at is the Display. The Display has two responsibilities: to continuously display a 2D texture containing the ultrasound image (without worrying about how it's rendered), and to initially set up all the classes necessary to generate the image. Find the Display object in the scene (it's a child object of the <em>Main Camera</em>). Look at the <strong>DisplayBehavior</strong> component in the inspector: there are 3 inspector variables. Texture Width and Height just change the dimensions of the texture on the display. You shouldn't need to change these very much, except to adjust for performance reasons.
 </p>
 <p>
    The <strong>Display Mode</strong> variable is very important - it actually determines the configuration of the entire rendering pipeline of the ultrasound image. It's set to <strong>HORAY</strong> by default. Recall that HORAY is a name for the ultrasound simulation model we are using. Try changing the Display Mode to <strong>InvHORAY</strong> and running the scene. You should see exactly the same image on the Display, but the colors have been inverted.
</p>
<p>
    Now try changing the Display Mode to <strong>FakeTexture</strong>. This sets up the Display to use a test class that provides a <em>constant</em> texture. You'll see that the display now shows vertical color bars, nothing resembling an ultrasound image. This is the simplest configuration possible - let's look at how it works.
</p>

<h2>DisplayBehavior with a TestTextureSource</h2>
<p>
    Open up the DisplayBehavior script. There are two private variables in this class:
</p>
<p>
    <code>
        private Texture2D texture;<br/>
        private ITextureSource textureSource;<br/>
    </code>
</p>
<p>
    <a href=http://docs.unity3d.com/Documentation/ScriptReference/Texture2D.html>Texture2D</a> is a built-in class in the Unity Engine, and allows us to programmatically change the texture of an object (rather than the more common use of static textures in games). <a href="./Docs/html/interface_i_texture_source.html" target="_blank">ITextureSource</a> is an interface describing a class that renders <em>some image</em> to a Texture2D - maybe an ultrasound image, or maybe horizontal color bars. We'll look more closely at it later, but for now, it's enough to just know that the <strong>textureSource</strong> variable is the class that's actually providing the texture for the display.
</p>
<p>
    Next, look at the Start( ) method in DisplayBehavior. It starts with a log statement, then the <strong>texture</strong> is instantiated and assigned to <strong>renderer.material.mainTexture</strong> - this just tells Unity3D that we'll be using a dynamic texture for the display. Next is a long switch statement, switching on the Display Mode value that we just changed in the Inspector. Recall that we set the mode to <strong>FakeTexture</strong> earlier. In the case for FakeTexture, we see the <strong>textureSource</strong> is set by the method <code>DisplayTexturePipelineFactory.BuildFakeTextureSource()</code>.
</p>
<p>
    "DisplayTexturePipelineFactory" sounds a bit like <a href="https://github.com/EnterpriseQualityCoding/FizzBuzzEnterpriseEdition/blob/master/src/main/java/com/seriouscompany/business/java/fizzbuzz/packagenamingpackage/impl/factories/EnterpriseGradeFizzBuzzSolutionStrategyFactory.java" target="_blank">something out of FizzBuzzEnterpriseEdition</a>, but it's not anything too terrible. It's just a factory class, and it's in the same file as DisplayBehavior if you scroll down a bit further. There is one method in the DisplayTexturePipelineFactory for each possible Display Mode. Several of the factory methods are a bit more complicated, but the method we're using, <strong>BuildFakeTextureSource()</strong>, just returns a new instance of <a href="./Docs/html/class_test_texture_source.html" target="_blank">TestTextureSource</a>.
</p>
<p>
    Now that we know that TestTextureSource is being used as the TextureSource for the Display, let's look at how the Display makes use of it. Scroll back up to the Update( ) method in DisplayBehavior. Remember that since DisplayBehavior extends <a href="https://docs.unity3d.com/Documentation/ScriptReference/MonoBehaviour.html" target="_blank">MonoBehaviour</a>, the Update( ) method is automatically called once every frame. Apart from some logging, the only action actually performed in the Update method is just a call to render the texture:<br/>
    <code>textureSource.RenderNextFrameToTexture(ref texture);</code>
</p>
<p>
    Now let's take a closer look at how <strong>TestTextureSource</strong> works. Actually, it's worth looking first at the interface for this class, <a href="./Docs/html/interface_i_texture_source.html" target="_blank">ITextureSource</a>. Only a single method is specified in this interface:<br/>
    <code>void RenderNextFrameToTexture(ref Texture2D texture);</code>
</p>
<p>
    TestTextureSource only has to implement this rendering callback method. Take a look at its implementation of <strong>RenderNextFrameToTexture</strong> - there are three important steps:
    <ol>
        <li>
            Instantiate an array of <a href="http://docs.unity3d.com/Documentation/ScriptReference/Color-ctor.html" target="_blank">Color</a> structs:<br/>
            <code>Color[] pixels = new Color[width * height];</code>
        </li>
        <li>
            Populate the color array (the body of the for loop).
        </li>
        <li>
            Render the color array "pixels" to the texture.<br/>
            <code>
                    texture.SetPixels(pixels);<br/>
                    texture.Apply();
            </code>
        </li>
    </ol>
    In fact, every other implementation of ITextureSource follows these same three steps. As long as we have a way to programmatically generate an array of Color structs matching the dimensions of the texture, we can render any image we want to our Display object.
</p>

<h2>Display with a FakeBModeProbeOutput</h2>
<p>
    Return to the inspector, and change the Display object's DisplayMode to <strong>FakeProbeOutput</strong>. When you hit play, you'll see something superficially resembling an ultrasound image, but, as the name suggests, this is also a fake image. However, with this mode enabled, we'll be able to step deeper through the display code than before.
</p>
<p>
    Remember that the DisplayMode variable is used in the Start( ) method of DisplayBehavior. This time, we call the method <strong>BuildWithFakeBModeProbeOutput</strong> to initialize our TextureSource. Here's the body of this factory method:<br/>
    <code>
        IProbeOutput fakeProbeOutput = new TestProbeOutput();<br/>
		IImageSource imageSource = new BModeOutputImageDecoder(fakeProbeOutput);<br/>
		return new TextureSource(imageSource);<br/>
    </code>
</p>
<p>
    We can imagine that our factory method is plugging these classes into one another, like so:<br/>
    <code>TestProbeOutput -> BModeOutputImageDecoder -> TextureSource -> Display</code><br/>
</p>
<p>
    As before, let's explore the code from the top down. We already know that the Display is receiving a Texture2D from the TextureSource class. Let's investigate the <strong>TextureSource</strong> class to see how it implements the RenderNextFrameToTexture callback. It follows the same pattern as our TestTextureSource did earlier:
    <ol>
        <li>
            Initialize a Color array (although it happens to be wrapped in a custom ColorBitmap struct).
        </li>
        <li>Populating the Color array is handled by the imageSource.<br/>
            <code>
                imageSource.RenderColorImageInBitmap(ref colorBitmap);<br/>
            </code>
        </li>
        <li>
            Render the Color array to the Texture2D.
        </li>
    </ol>
    Recall that in the factory method, a BModeOutputImageDecoder was "plugged in" to the TextureSource. So, in this case, BModeOutputImageDecoder is the imageSource that provides a ColorBitmap to the TextureSource. Before we look at details in the BModeOutputImageDecoder class, let's look at its interface, <a href="./Docs/html/interface_i_image_source.html" target="_blank">IImageSource</a>. Two methods are declared here: RenderColorImageInBitmap method and AddPostProcessingEffect. For now, don't worry about post-processing. RenderColorImageInBitmap in IImageSource is conceptually very similar to the RenderNextFrameToTexture in ITextureSource. TextureSource just expects its ImageSource to be able to provide some sort of ColorBitmap.
</p>
<p>
    (As an aside, a <a href="./Docs/html/struct_color_bitmap.html" target="_blank">ColorBitmap</a> is just a struct containing a Color array along with the dimensions (height and width) of the bitmap.)
</p>

<h2>The BModeOutputImageDecoder</h2>
<p>
    Let's take a closer look at the BModeOutputImageDecoder now. Specifically, look at the <strong>RenderColorImageInBitmap</strong> method. There are three key steps in this method:
    <ol>
        <li>
            Acquire data from an <a href="./Docs/html/interface_i_probe_output.html" target="_blank">IProbeOutput</a>
        </li>
        <li>
            Render the data into discrete points on the bitmap.
        </li>
        <li>
            Apply post-processing effects.
        </li>
    </ol>
    Remember that our ProbeOutput in this case is a <strong>FakeProbeOutput</strong>, so we won't worry how it generates the data. However, let's look at the data structure that is returned, an <a href="./Docs/html/class_ultrasound_scan_data.html" target="_blank">UltrasoundScanData</a> object.
</p>
<p>
    For all intents and purposes, an UltrasoundScanData object is structurally just a <a href="http://msdn.microsoft.com/en-us/library/2s05feca.aspx" target="_blank">jagged array</a>. The "outer" array is a list of <a href="./Docs/html/class_ultrasound_scanline.html" target="_blank">UltrasoundScanline</a> objects. Each UltrasoundScanline is a discrete trajectory through space, radially omitted from the ultrasound probe. Then, points along each UltrasoundScanline are sampled to create "inner" arrays of discrete <a href="./Docs/html/class_ultrasound_point.html" target="_blank">UltrasoundPoints</a>. For now, think of an UltrasoundPoint as a tuple &ltX,Y,Z,B&gt, where X Y Z are the coordinates in world space of that UltrasoundPoint, and B is the "brightness" of that point, as it should appear when rendered in the ultrasound image.
</p>
<p>
    Here is an example of a hypothetical UltrasoundData object called "data":</br>
    <code>
    data[0] = scanline along vector (1,2,3) = <0,0,0,1> -> <1,2,3,1> -> <2,4,6,0> -> <3,6,9,1></br>
    data[1] = scanline along vector (0,0,1) = <0,0,0,1> -> <0,0,1,1> -> <0,0,2,0> -> <0,0,3,0></br>
    data[2] = scanline along vector (0,1,0) = <0,0,0,1> -> <0,1,0,1> -> <0,2,0,1> -> <0,3,0,1></br>
    </code>
</p>
<p>
    Let's return to our BModeOutputImageDecoder and see how this data is rendered. Since the UltrasoundScanData is a jagged array, it makes sense to iterate through the data with a nested for-loop. The basic pseudo-code of this iteration process is:<br/>
    <code>
    foreach (UltrasoundScanline scanline in data)<br/>
    foreach (UltrasoundPoint point in scanline)<br/>
    draw(point);<br/>
    </code>
</p>
<p>
    The draw code is actually a bit more complicated than that - first we have to figure out which pixel coordinate that point should be drawn to (computed by the <strong>MapScanningPlaneToPixelCoordinate</strong> method), but those details aren't critical to understand. All that is really necessary to know is that the BModeOutputImageDecoder can generate a bitmap representation of the data in an UltrasoundScanData.
</p>
<p>
    Remember how in the Overview section I said that we can think of the "host" project as separate from the actual ultrasound simulation? At this point, you've seen all the basics of the host project pertaining to image display. Next, we'll look at the ultrasound simulation portion - specifically, how the <strong>HORAY</strong> system can be used to populate an UltrasoundScanData object.
</p>
</body>
</html>